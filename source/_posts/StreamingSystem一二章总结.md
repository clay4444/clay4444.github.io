---
title: StreamingSystem一二章总结
categories:
  - StreamingSystem读书笔记
abbrlink: 613fbfdf
date: 2019-02-11 17:12:46
---

### autor

Tyler

Google数据处理语言和系统小组的技术负责人，负责Google Cloud Dataflow，Google的Apache Beam工作，以及Google内部数据处理系统，如Flume，MillWheel和MapReduce。我也是Apache Beam PMC的创始成员；

<br/>

Slava

Slava是Google的MillWheel团队的长期成员，后来成为Windmill团队的原始成员，该团队构建了MillWheel的继任者，这是迄今为止未命名的系统，为Google Cloud Dataflow中的Streaming Engine提供支持。 Slava是全世界流媒体处理系统中水印和时间语义的最重要专家。你可能会发现他是第3章水印的作者并不令人惊讶。

<br/>

Reuven

Reuven创建领导了Google通用流处理引擎中几乎所有有趣的系统级应用的创建，包括在提供高吞吐量，低延迟，一次性语义的过程中对细节提供了无数的关注。但是，系统仍然使用细粒度的检查点。您可能会发现他是第5章，精确一次和副作用的作者并不令人惊讶。他恰好也是Apache Beam PMC成员。

<br/>

chapter1

流处理基本知识

<br/>

chapter2

详细介绍了对无序数据进行稳健流处理的核心概念

<br/>

chapter3 （slava）

watermark

<br/>

chapter4

高级窗口

<br/>

chapter5

exactly-once 和 side Effects，

<br/>

chapter6

stream and table 流和表的基本思想

<br/>

chapter7

状态管理机制

<br/>

chapter8

Streaming sql

<br/>

chapter9

join

<br/>

#### 最重要的两个概念

1. 您可以从本书中学到的最重要的一点是流和表的理论知识以及它们之间的关系。其他一切都建立在其基础之上
2. 时变关系是一个启示。它们是流处理的化身：所有流媒体系统的创建都是为了实现和我们熟悉的工具的强大连接而实现的。

<br/>

### chapter1

定义数据特征的两个重要维度：基数(cardinality)和构成(constitution)

Cardinality 定义了有界数据还是无界数据

constitution定义了与数据的交互方式（stream和table）

lambda架构中：流媒体系统：低延迟，不准确，只是推测的结果，要和批处理系统结合使用；

观点：流处理和批处理应该统一

成熟的流计算系统+强大的无界流数据处理框架将完全取代Lambda 架构，只需要做两件事：

1. 强大的数据**一致性**和准确性：通过checkpoint persistent state，exactly-once
2. 推理时间的工具：尤其是对于无限、无序数据集

<br/>

#### event time vs processing time

理想状态下：事件时间应该和处理时间相等，但是现实世界中：事件时间和处理时间之间的差距不仅不为0，而且还是随着输入数据的特点、执行引擎、和硬件等等高度相关的函数；

{% asset_img figure1-1.png %}

<br/>

其中：processing time distance (垂直) 代表的值的意义是：处理时间的延迟，也就是事件的产生和事件的真正处理之间的延迟；

event time distance (水平) 代表的值的意义是：事件时间的延迟

实际上这两个值是完全相等的，他们只是观察数据的两种不同的视角；

<br/>

由于event time 和 process time 之间的整体映射不是静态的，即时间的滞后或者说延迟可能随时间任意变化，所以如果想通过事件时间分析数据，那么通过一些无界数据处理框架是无法实现的，因为它们仅提供了以处理时间为基准的窗口，此时的分析的结果就是不准确的；

<br/>

如果按照事件时间进行窗口切分：那么带来的挑战就是事件时间窗口的完整性问题，如何确定何时观察到给定事件时间窗口的所有数据？对于很多真实的数据源，这根本不可能做到，目前使用的绝大多数数据处理系统都依赖于某些固定的完整性概念，这使得它们在应用于无界数据集 (stream) 时处于严重劣势

<br/>

不要试图将无限数据整理成最终变得完整的有限批次信息，而应该设计工具，让我们生活在这些复杂数据集所带来的不确定性世界中。新数据将会到来，旧数据可能会被撤回或更新，我们构建的任何系统都应该能够自行处理这些事实，完整性概念是对特定和适当用例的方便优化，

<br/>

#### 常见的数据处理模式

有界数据

经典批处理，mr

<br/>

无界数据：

第一种处理方法：Batch ( 批次 )：此类方法围绕将无界数据切割为适合批处理的有界数据集的集合

<br/>

fix window

问题：数据完整性，数据延迟导致的，

解决方案：直到确定已收集所有事件； 或在迟到数据到达时，重新计算，

<br/>

sessions

当尝试使用批处理引擎将无限数据处理为更复杂的窗口策略（如会话）时，此方法会更加崩溃。使用典型的批处理引擎计算会话时，您经常会遇到按批次分割的会话，如下图中的红色标记所示。我们可以通过增加批量来减少拆分数量，但代价是延迟增加。另一种选择是添加额外的逻辑来拼接先前运行的会话，但代价是进一步复杂化

{% asset_img figure1-4.png %}

<br/>

第二种处理方法：Streaming

数据特点：

1. 无界
2. 高度无序
3. 事件时间偏差随机，意味着你不能只假设你总是会在某个恒定的时间ε中看到给定事件时间X的大部分数据。

<br/>

处理方法分类：

1. 时间不可知

与时间无关，所有的逻辑都是数据驱动的，简单的将无界数据源分割为有限数据集的序列并独立处理，批处理系统也非常适合无界数据源的这种时间无关的情况，

举例：

Filter 过滤网络流量日志，数据无界，无序，不影响处理；

{% asset_img figure1-5.png %}

<br/>

innner join 

{% asset_img figure1-6.png %}

将语义切换到某种外连接会引入我们所讨论的数据完整性问题：在我们看到连接的一侧之后，您如何知道另一方是否会到达？说实话，你没有，所以你需要引入一些超时的概念，这会引入一个时间元素。**时间元素本质上是一种窗口形式**

<br/>

1. 近似

各种分类，聚类算法

<br/>

1. windowing by procesing time

好处：

1. 实现非常简单，因为不用担心在一段时间内对数据进行shuffle。你只需在它们到达时缓冲它们并在窗口关闭时将它们发送到下游
2. 判断窗口的完整性很简单。由于系统完全了解是否已经看到窗口的所有输入，因此可以就给定窗口是否完整做出完美的决定。这意味着当按处理时间进行窗口化时，无需以任何方式处理“延迟”数据
3. 如果您想要在数据处理时推断出有关源的信息，那么处理时间窗口正是您想要的。许多监测方案都属于这一类

<br/>

缺点：

如果有问题的数据具有与它们相关联的事件时间，那么如果处理时间窗口要反映实际时间，则这些数据必须按事件时间顺序到达

<br/>

1. windowing by event time

{% asset_img figure1-10.png %}

<br/>

好处：

1. 可以准确的反映时间发生的时间
2. 另一个好处是，您可以创建动态大小的窗口，例如会话窗口，而不会在通过固定窗口生成会话时观察到任意分割，

<br/>

两个明显的缺点：

1. 由于延长了窗口寿命，因此需要更多的数据缓冲，值得庆幸的是，持久存储通常是大多数数据处理系统所依赖的资源类型中最便宜的（硬盘，ssd等）。因此，当使用任何设计良好的数据处理系统（具有强一致的持久状态和涉及良好的内存缓存层）时，这个问题通常不像您想象的那么令人担忧。而且，许多有用的聚合不要求整个输入集被缓冲（例如，总和或平均），而是可以递增地执行，其中存储在持久状态中的小得多的中间聚合。
2. 数据完整性问题，借助watermark给出窗口完成的合理、准确的启发式估计，对于绝对准确性的情况，唯一的方式是**数据管道中能够给出一种方式来表达何时数据已经完整了，以及如何随时间推移数据**

<br/>

<br/>

### chapter2

#### Triggers 触发器

触发器是一种机制，用于声明相对于某些外部信号何时应该实现窗口的输出。触发器可灵活选择何时应发出输出，触发器还可以随着演变而多次观察窗口的输出。这反过来打开了**随着时间的推移改进结果**的大门，这允许**在数据到达时提供推测结果**，以及**随时间推移上游数据或（修订）迟到的数据**

<br/>

#### Watermarks

是关于事件时间的输入完整性的概念，具有时间X值的水印的概念：“已经观察到事件时间小于X的所有输入数据，充当进度的度量

<br/>

#### Accumulation  累积模式

<br/>

累积模式指定在同一窗口中观察到的多个结果之间的关系。这些结果可能完全脱节;也就是说，随着时间的推移表示独立的增量，或者它们之间可能存在重叠
这里可以参考session窗口

<br/>

#### 四个问题

1. what 计算结果是什么？

sum，直方图，训练模型，等，基本上也是经典批处理所回答的问题

<br/>

1. where  使用事件时间时，在哪里计算结果

Window：使用事件时间窗口，窗口结束的时间就是计算结果的时间点

<br/>

1. when  在处理时间内是否实现了结果  ( 个人理解：数据是否完全到达，或者达到了大部分，可以计算结果 )

通过使用触发器和（可选地）水印来回答该问题。

<br/>

1. how  结果的细化如何相关？ (各个结果之间如何关联)

通过所使用的累积类型来回答：丢弃（其中结果都是独立的和不同的），累积（其中后面的结果建立在先前的结果上），或累积和缩回（其中累积值加上回退）

<br/>

#### 批处理基石：what  where

处理有界数据的数据源

举例：userSocres

假设我们已经编写了一个基于团队的手机游戏，我们希望建立一个通过总结用户手机上报的个人得分来计算团队得分的数据pipline。如果我们要在名为“UserScores”的SQL表中展示我们的九个示例分数，它可能看起来像这样：

<br/>

| Name  | Team  | Score | EventTime | ProcTime |
| ----- | ----- | ----- | --------- | -------- |
| Julie | TeamX | 5     | 12:00:26  | 12:05:19 |
| Frank | TeamX | 9     | 12:01:26  | 12:08:19 |
| Ed    | TeamX | 7     | 12:02:26  | 12:05:39 |
| Julie | TeamX | 8     | 12:03:06  | 12:07:06 |
| Amy   | TeamX | 3     | 12:03:39  | 12:06:13 |
| Fred  | TeamX | 4     | 12:04:19  | 12:06:39 |
| Naomi | TeamX | 3     | 12:06:39  | 12:07:19 |
| Becky | TeamX | 8     | 12:07:26  | 12:08:39 |
| Naomi | TeamX | 1     | 12:07:46  | 12:09:00 |

{% asset_img figure2-1.png %}

<br/>

what = Transformations(计算方式)

批处理，累积所有的状态，直到看到所有的输入，最终返回结果，

{% asset_img figure2-3.png %}

<br/>

上面是有界数据的处理形式，无界数据中，不可能缓存所有的状态，
此时的问题：事件时间在哪里计算结果？

<br/>

where  =  Windowing （窗口化）

批处理只是流处理的一个子集，

此时event time 生成四个结果，12:00 - 12:02  02 - 04   04 - 08   08 - 10，而不是批处理的一个结果，

对于四个相关的两分钟事件时间窗口中的每一个，我们得到四个输出；

{% asset_img figure2-5.png %}

<br/>

#### streaming  ：when

我们刚观察了批处理引擎上窗口pipline的执行情况。但是，理想情况下，我们希望我们的结果具有较低的延迟，并且我们还希望处理**无界数据源**。切换到流媒体引擎是朝着正确方向迈出的一步，但是我们之前等待我们的输入被全部消耗以生成输出的策略已不再可行。此时我们需要的东西是：触发器和水印。

<br/>

when    （触发器）

Triggr：在一个事件时间窗口处理过程中，何时发生窗口的输出；

( 尽管触发器本身可能根据其他时域中发生的事情做出这些决定，正如水印在事件时间域中的进展，我们将在稍后看到  ) 

窗口的每个特定输出称为窗口的窗格

<br/>

两种通常有用的触发类型：

1. 重复更新触发器 ( 最常见的，最容易实现且最容易理解 )

 这些窗口随着内容的发展而定期生成窗口的更新窗格。这些更新可以在每个新记录中实现，也可以在一些处理时间延迟后发生，例如每分钟一次。重复更新触发器的周期选择的主要依据是平衡延迟和成本；

<br/>

1. 完整性触发器

   只有在认为该窗口的输入完成某个阈值之后，这些才会实现窗口的窗格。这种类型的触发器与我们在批处理中熟悉的类似：只有在输入完成后才提供结果。基于触发器的方法的不同之处在于，**完整性的概念限定在单个窗口的上下文中，而不是始终受限于整个输入的完整性**

​    完整性触发器不常遇到，但提供的流式语义更接近经典批处理世界的流式语义。它们还提供了推理缺失数据和后期数据之类的工具，我们在讨论完整性触发的基础原语时会很快（在下一章）讨论这些工具：水印

<br/>

**重复更新触发器** 举例：单个窗口，多个输出 ( 每条记录生成一个结果 )

{% asset_img figure2-6.png %}

<br/>

重复更新触发器  之 每条记录触发一次：

可以看到我们现在如何为每个窗口获取多个输出（窗格）：每个相应的输入一次。当输出流被写入某种表格时，这种触发模式很有效，可以简单地轮询结果。无论何时查看表格，您都会看到给定窗口的最新值，这些值将随着时间的推移而趋于正确（一直都是最新的结果）

每条记录触发一个窗口的缺点：处理大规模数据时，sum，count等聚合操作是一个很好的机会来减少流的基数而不会丢失信息，直接累加状态每次更新即可，此时如果使用延迟处理时间更新，效果会好很多，因为他们会对数据进行类似打散操作，也就是说要存储的状态变小了；结果也是准确的

<br/>

重复更新触发器  之 处理时间延迟后触发：

1. 对齐延迟（根据处理时间再划分**处理时间窗口**(区别于上述的事件时间窗口)，划分成固定处理时间长度的窗口）：

{% asset_img figure2-7.png %}

类似于spark streaming，每次跑一个小批次，优点是：可以同时在所有修改过的窗口中定期更新，缺点是：所有更新都会立即发生，从而导致突发性工作负载通常需要更高的峰值配置才能正确处理负载

<br/>

1. 未对齐延迟（其中延迟相对于给定窗口内观察到的数据，也就是观察到一条数据之后，根据这条数据的处理时间，再延迟一段固定时间）

{% asset_img figure2-8.png %}

未对齐延迟如何在一段时间内更均匀地分散负载？任何给定窗口所涉及的实际延迟（最终的处理时间的延迟时间）在每个事件时间窗口之间有所不同，有时更多，有时更少（01到02之间处理时间延迟更多，02到04之间处理时间延迟更少），但最终平均延迟将保持基本相同。从这个角度来看，未对齐延迟通常是大规模处理的更好选择，因为它们会随着时间推移产生更均匀的负载分布

<br/>

重复更新触发器  之 适用情况 总结：

重复更新触发器非常适用于我们只希望随着时间的推移定期更新结果的用例，并且这些更新收敛于正确性但是**没有明确指示何时进行计算是正确的**;

但是对于数据完整性要求非常高的情况，而分布式系统的变幻莫测又意味着很难推断出输出的时间提供准确完整的输入数据视图，此时需要的解决办法就是：要有一些推理完整性的方法，而不是盲目地信任计算结果，这些结果是通过恰好已经在管道中存在的数据来计算的；
这就是**watermark的作用**；

**同时，watermark 也解决了事件时间窗口状态何时可以删除的问题 (allow latency)**

<br/>

when    （watermark）

是**系统测量进度和完整性**的方式

{% asset_img figure2-9.png %}

图中现实世界的处理过程基本上就是水印，它随着处理时间的推移捕获事件时间完整性的进度。从概念上讲，您**可以将水印视为一个函数F（P）→E，它取决于处理时间并返回事件时间点。 事件时间中的那个点E是系统认为所有输入事件时间小于E的输入点**。换句话说，这是一个断言，不会再看到事件时间小于E的数据

<br/>

两种水印：

1. 完美水印：**严格的保证**

对所有输入数据有完全了解的情况，构建完美的水印

1. 启发式水印：**有根据的猜测**

启发式水印使用有关输入的任何可用信息，来提供尽可能准确的进度估计。在许多情况下，这种水印在其预测中可以非常准确。即便如此，**使用启发式水印意味着它有时可能是错误的**，此时就需要处理延迟数据；

<br/>

因为水印提供了相对于我们输入的完整性概念，所以水印形成了前面提到的第二类触发器的基础：完整性触发器，也就是说：**水印就是一种完整性触发器**

<br/>

给定的数据集可以应用不同的水印，当我们对输入数据完全了解的情况下，我们可能会创造一个完美水印，但是如果不够了解，或者完美水印成本太大，可以选用启发式脚本，左图是完美水印，右图是启发式；

在这两种情况下，当水印通过窗口的末端时，意味着窗口结束，可以计算结果；

{% asset_img figure2-10.png %}

水印 ( 完整性触发器 ) 和我们在图2-5到2-7中看到的重复更新触发器之间的巨大差异在于**水印为我们提供了一种推理输入完整性的方法**。在系统实现给定窗口的输出之前，我们知道系统还不确定输入是完整的。这对于您想要推断输入中丢失数据或延迟数据尤为重要；

<br/>

处理outer join情况，何时放弃并发出部分连接而不是继续等待连接完成？缺乏真正水印支持的流媒体系统的常用方法是基于处理时间，然后延迟固定时间做出决定，但是这种处理方法是不靠谱的，因为**事件时间偏差有各种可能性（和多种因素有关，例如某个固定时间点数据峰值，有时数据处理很快，有时数据处理很慢）**；从这个角度来看，事件时间水印是许多真实流媒体用例的关键部分，它必须可以推断出输入流中的延迟数据；

<br/>

水印的两个缺点：

1. 太慢：延迟性

这是显而易见的，水印会推断数据有没有到齐，如果没有到齐，肯定会等待并处理延迟数据，尤其是对于完美式水印来说，

如2-10 的左图情况，为了等待12:00 - 12:02 中迟到的数据9，处理时间一直等待了9分钟才处理完，严重延迟了获得窗口结果的时间；虽然左图是完美式水印，但是启发式的水印同样会有这样的问题，只是在图中没有表示出来；

尽管水印提供了一个非常有用的完整性概念，但从延迟的角度来看，根据产生输出的完整性而采用缓存窗口内数据并最终计算一次通常并不理想。想象一个仪表板，其中包含有价值的指标，按小时或天显示。您不太可能想要等待整整一小时或一天才能看到当前窗口的结果;这是使用传统批处理系统为这些系统提供结果的难点之一。相反，**随着输入的发展并最终变得完整**，**随着时间的推移，这些窗口的结果会变得更好，才是好的解决方案**

<br/>

1. 太快 ( 有时会出错，即丢掉了部分延迟数据 )  ：数据的不准确性

当启发式水印错误地提前超过真正的水印时，就会出现延迟数据。这就是右边示例中发生的情况：在观察到该窗口的所有输入数据之前，水印超过了第一个窗口的末尾，导致输出值不正确而不是14。这个缺点严格来说是启发式水印问题，**他们的启发性意味着他们有时会出错**。因此，如果您关心正确性，单靠启发式水印来确定何时实现输出是不够的。

<br/>

**突破点 ( 厉害的点 )** ：重复更新触发器解决了低延迟的问题，但无法保证数据的完整性，watermark提供了推断完整性的概念但是可能会导致较高的延迟，so，为什么不将他们组合在一起呢？

<br/>

when ( 早期 / 准时 / 晚期 )  触发器：本质其实就是：**重复更新触发器 + 完整性触发器 ( wtermark )**    

Beam提供了一种水印(完整性触发器)的扩展，该触发器还支持水印两侧的重复更新触发，称为早期/准时/晚期触发器

<br/>

1. 早期触发器：

0个或多个watermark，属于**重复更新触发器**，定期触发，直到窗口结束，允许我们随着新输入数据的到来观察窗口随时间的演变。这**弥补了水印有时会产生延时的缺点**。

1. 准时触发器

单个准时触发器，属于**完整性触发器(watermark)**，本质是一种断言，窗口看到这个触发器说明此窗口数据已经完整了；

1. 延迟触发器

0个或多个延迟的触发器，是**一种特殊的重复更新触发器**，在准时触发器(水印)通过窗口结束后，**延迟数据到达时触发**，所以完美水印的情况下，此值一直为0，但启发式水印下，可能会触发，**弥补了水印太快导致数据错误的缺点**

<br/>

现在，在我们的数据pipline中，使用此**周期性处理时间触发器(也就是上述三个触发器组合的方式)**，对于早期数据，使用触发器且对齐延迟为一分钟，对于晚期数据，使用延迟触发器。这样，早期的启动将为我们提供大量窗口的批量处理（由于触发器每分钟只会触发一次，无论窗口的吞吐量如何），如果我们使用相当准确的启发式水印，那么对于晚期数据，我们不会引入不必要的延迟(当然：这件事的希望有些渺茫)

{% asset_img figure2-11.png %}

<br/>

对于数据延迟的问题来说，每分钟一次的定期更新触发器，很大程度缓解了水印太慢的情况，如图，无论是完美式水印或者启发式水印，每隔一分钟就会有输出，用户体验也好了，数据延迟也是最低的；

对于数据准确性的问题来说，12:00 - 12:02 丢失的数据9，后来也合并到了5上，变成了14，解决了数据丢失的问题；

<br/>

由于使用了水印触发器，我们还可以推断出我们生成的结果中的输入，使我们可以更好地处理和关注产生延迟数据的情况，以便及时发现系统可能存在的问题；

<br/>

<br/>

when   ( allow latency  )

完美式水印和启发式(早期 / 准时 / 延迟  ( 触发器 ) ) 之间最大的差异是**窗口生命周期限制**。在完美的水印情况下，我们知道在**水印结束后我们永远不会再看到窗口的数据**，因此我们可以在那时删除窗口的所有状态。在启发式水印的情况下，我们**仍然需要保持一个窗口的状态一段时间来考虑后期数据**。但到目前为止，**我们的系统没有任何好的方法可以知道每个窗口需要保持多长时间状态**。这就是**allow latency** 出现的原因

<br/>

在长期无序的流处理系统中的垃圾收集的重要性：在图2-11中的启发式水印示例中，每个窗口的持久状态在示例的整个生命周期中一致存在，这是必要的，以便我们能够在他们到达时适当处理迟到的数据。但是，虽然能够保持所有持久状态直到时间结束会很棒，但实际上，在处理无限数据源时，无限期地保持给定窗口的状态（包括元数据）通常是不切实际的。 我们最终会耗尽磁盘空间 ( 不能无限期的保存事件时间窗口的数据 )

<br/>

注意点:  之前我曾有些纠结点：延迟触发器 的作用不就是处理延迟数据的吗？为什么还要allow latency 呢？其实想一下就会明白，我们不能一直保存着每个事件时间窗口的所有状态数据，这也就是导致了：延迟触发器不可能一直有效果，**allow latency 过期的时候，也就是延迟触发器失效的时候**

<br/>

因此，任何一个流系统都需要提供一个方法限制它正在处理的事件时间窗口的生命周期。一种干净简洁的方法是通过定义系统内允许的迟到范围;也就是说，限制任何给定记录的延迟时间（**相对于水印**），系统要对其进行处理;任何在此视野之后到达的数据都会被删除。在你限制了个别数据的延迟之后，你还确切地确定了窗口的状态必须保持的时间范围：直到水印超过窗口末端的延迟范围。

<br/>

关键点：我们使用水印（针对的是**事件时间**）作为窗口结束的标志的原因是：可用的选项中它是做好的，另一个选择是指定处理时间的范围（例如，**在水印通过窗口结束后保持窗口处理10分钟的处理时间**），但使用处理时间会使垃圾收集策略容易受到问题的影响，例如数据处理pipline的过程中崩溃了几分钟，而这几分钟正是我们处理延迟数据的几分钟， 这可能导致窗口实际上没有机会处理他们原本应该处理的延迟数据，但是通过在事件时间中(也就是水印) 指定范围，**垃圾收集直接与管道的实际进度相关联**，降低了窗口错过其适当处理延迟数据的机会的可能性，也就是说：如果数据处理pipline中整体数据处理的比较慢，那么watermark 这条曲线就比较陡，那么allow latency 延迟时间就会比较长，也就是需要更多的时间处理延迟数据，而如果watermark 这条曲线变得比较平缓了，说明此时数据处理就比较快了，那么此时allow latency 延迟时间就会比较短，这也是垃圾收集直接与管道的实际进度相关联的意思。

<br/>

我们所说的水印一般情况下都是**低水位标记**：它们会悲观地尝试捕获系统所知道的最旧的未处理记录的事件时间，通过这种方式处理延迟数据的好处是它们能够适应事件时间偏差的变化，无论管道中的偏差 ( 处理时间减去事件时间 )有多大，低水印都将始终跟踪系统已知的最古老的突出事件，从而提供可能的正确性的最佳保证。

<br/>

相反，一些系统可能使用术语“水印”来表示其他事物。例如，Spark Structured Streaming中的水印是高水印，它乐观地跟踪系统所知道的最新记录的事件时间。当处理迟到时，系统可以自由地收集在这个时间段内的延迟数据( 这个时间段指的就是高水印时间减去用户指定的阈值 )  换句话说，系统允许您指定预期在管道中看到的最大事件时间偏差量，然后丢弃该窗口之外的任何数据。**如果管道中的偏差保持在某个恒定的增量范围内，这可以很好地工作**，但是比低水印方案更容易产生丢失数据。

<br/>

一分钟的水印延迟图示

{% asset_img figure2-12.png %}

注意点：延迟范围指的是，水印延迟一分钟，也就是：**事件时间延迟一分钟，然后对应的处理时间，就是窗口的最终结果**，  而不是处理时间延迟一分钟，

<br/>

仅对于此图，我为第一个窗口添加了一个额外的后期数据，其值为6，这6个是迟到的，但仍然在允许的延迟范围内，因此被合并到值为11的更新结果中。然而，9超过了最终的处理时间点，所以它直接被丢弃了

<br/>

如果您正在使用来自可获得完美水印的数据源的数据，则无需处理延迟数据，并且允许零秒的延迟时间范围将是最佳的

<br/>

<br/>

#### streaming  : how   ：数据之间如何联系

当触发器用于为一个窗口生成多个窗格时（重复更新触发器触发一次，就生成一个窗格），我们发现自己遇到了最后一个问题：“结果的细化如何相关？”在我们到目前为止看到的示例中，每个窗格产生的数据都累加到前一个窗格的数据之上。然而，实际上有三种不同的积累方式：

1. 丢弃模式：对于每一个pane的输出结果都是独立的。
2. 累积模式：每次实现窗格结果时，都会保留所有的存储状态，并且将来的输入数据将累积到现有状态。这意味着每个连续的窗格都基于先前的窗格。**当后续结果可以简单地覆盖以前的结果时**，累积模式很有用，例如将输出存储在HBase或Bigtable等键/值存储中时
3. 累加和撤回：与累加模式大致相同，不同的地方是：输出新的状态的时候，**撤销并替换上个状态的结果**；在以下两种情况时比较有用
   1. 当下游消费者按不同维度重新组合数据时，新值最终可能最终与前一个值不同，因此最终会出现在不同的组中。在这种情况下，新值不能只覆盖旧值，此时需要撤消以删除旧值
   2. 动态表

<br/>

考虑图2-11中的第二个窗口（具有事件时间范围[12：06,12：08）的窗格）

这三种模式下的情况如下表格所示

|             | 丢弃模式 | 累积模式 | 累积+撤回模式 |
| ----------- | -------- | -------- | ------------- |
| pane1       | 3        | 3        | 3             |
| pane2       | 9        | 12       | 12,-3         |
| pane        | 9        | 12       | 12            |
| sum of pane | 12       | 15       | 12            |

<br/>

1. 丢弃模式

每个窗格仅包含在该特定窗格期间到达的值。因此，观察到的最终值并未完全捕获总和。但是，如果您要自己对所有独立窗格求和，则会得到12的正确答案。这就是当下游消费者本身在物化窗格上执行某种聚合时，丢弃模式很有用的原因。

<br/>

1. 累积模式

每个窗格都包含在该特定窗格期间到达的值以及先前窗格中的所有值。因此，正确观察到的最终值会捕获12的总和。但是，如果您要自己总结各个窗格，那么您实际上会对窗格1中的输入进行重复计算，从而得出不正确的总和15，这就是为什么当你可以用新值覆盖以前的值时，累积模式最有用的原因：**新值已经包含了到目前为止看到的所有数据**

<br/>

1. 累积&撤回模式

**每个窗格都包含新的累积模式值以及前一个窗格值的撤回**。因此，观察到的最后一个值（不包括撤回）以及所有物化窗格的总和（包括撤消）都为您提供了12的正确答案。这就是撤消如此强大的原因。

<br/>

丢弃模式图示

{% asset_img figure2-13.png %}

此丢弃版本中的任何窗格都不会重叠。结果，每个输出pane都独立于其他输出pane

<br/>

撤回模式图示

{% asset_img figure2-14.png %}

撤回用红色表示，它与重叠的蓝色窗格结合，产生略带紫色的颜色

<br/>

整体对比图示

{% asset_img figure2-15.png %}

<br/>

这三种模式：在存储和计算成本方面逐步提高，需要我们在正确性，延迟和成本方面进行权衡

<br/>

#### 总结

Windowing：通过在时间边界上切片来管理无界数据的常用方法，但是在以后的讨论中大部分都都是基于事件时间

<br/>

Triggers：用于精确指定窗口输出的时机

<br/>

Watermarks：事件时间进展的强大概念，提供了一种在无界数据上运行的无序处理系统中推理完整性（从而丢失数据）的方法

<br/>

Accumulation：单个窗口的结果细化之间的关系