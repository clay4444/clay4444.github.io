---
title: kafka权威指南第七八章
categories:
  - kafka权威指南读书笔记
abbrlink: 3308668f
date: 2019-05-19 16:01:14
---

## 第七章：数据管道

<br/>

当我们使用Kafka来构建数据管道的时候，通常有两种主要的场景：1）Kafka是数据的起点或终点，比如从Kafka传输数据到S3或者从MongoDB传输数据到Kafka；2）Kafka作为数据的中间缓冲区，比如构建Twitter到Elasticsearch的数据管道时，Twitter先把数据传输到Kafka，然后Kafka再将数据传输到Elasticsearch。

使用Kafka构建数据管道可以将数据的生产者和消费者进行解耦，并且能够保证高可靠以及高性能。另外在0.9版本，Kafka加入了Kafka Connect这个新的API，使得将Kafka集成到数据管道更加方便。

下面来看下数据管道的一些具体细节。

<br/>

### 构建数据管道的考虑因素

<br/>

#### 时间线

在实际中，有一些系统的数据可能每天进行一次数据处理，有一些系统可能希望数据从产生到消费只有毫秒级延迟，而另外的系统则介于这两个极端之间。一个优秀的数据集成系统应当能满足不同场景的时间线要求，并且能够支持时间线的迁移（因为实际应用中需求是不断变化的）。Kafka具备这样的性质，既支持准实时的数据传输，也支持定时的批量数据传输，并且保证数据可靠存储以及水平扩展。在Kafka中，生产者可以根据需要来决定写入Kafka的时机，而一旦数据到达Kafka，消费者可以立即读取（其实消费者也可以定时批量读取，取决于使用场景）。

在这个场景中，Kafka充当数据的大缓冲区角色，并且解耦了生产者与消费者的时间敏感度要求：生产者可以实时产生数据而消费者定期消费数据，反之亦然。

<br/>

#### 可靠性

我们需要避免单点故障，并且在发生故障时能够快速的自动恢复。对于核心系统来说，即便是秒级的不可用也有可能造成巨大的损失，因此系统可用性极为重要。另外，数据传输可靠性也非常重要，一些系统能够容忍数据丢失，但更多情况下业务需要的是至少一次（at-least-once）的数据传输保证。至少一次意味着数据一旦生产成功，那么必定会到达终点，但有可能会出现数据重复出现的情况。在某些情况下，我们甚至需要有且仅有一次（exactly-once）的数据传输，这意味着数据一旦生产必须到达终点，而且不允许数据丢失或者重复。

我们讨论过了Kafka的可用性和可靠性。Kafka本身能够提供至少一次的数据传输，而通过与外部系统（具备事务性质或者支持唯一键）结合使用能够保证数据有且仅有一次的语义。值得一提的是，Kafka Connect这个API让外部系统与Kafka结合更为方便，使得实现端到端的有且仅有一次的语义更简单。

<br/>

#### 高吞吐

数据管道一般需要支持高吞吐，而且更为重要的是在流量激增的情况下仍然能正常运行。通过使用Kafka，我们可以将生产者与消费者的处理能力进行解耦。如果某个时刻生产者的生产速度远超于消费者的消费速度，那么数据会存放在Kafka中直至消费，也就是说Kafka具备流量削峰的特性。另外，我们可以通过增加消费者或者生产者来分别提高两端的处理能力。

总的来说，Kafka是一个高吞吐的分布式系统，在集群情况下每秒处理百兆级别的数据并不是什么难事，我们也不需要担心在数据量增长的情况下系统不能横向扩展。另外，Kafka Connect使得数据处理不仅可以横向扩展，并且可以并行化，后面我们会深入讨论这一点。

<br/>

#### 数据格式

构建数据管道的一个重要考虑因素是不同数据格式的支持程度。在实际应用中，我们的数据库或者其他存储系统的存储格式通常是多种多样的，比如说可能源数据格式是XML或者关系型的，存储到Kafka中是Avro类型的，最后可能需要转换成JSON格式以便写入Elasticsearch。

Kafka能够满足不同的数据类型要求，在前面系列文章中，我们讨论过生产者和消费者如何使用不同的序列化/反序列化来支持多种数据格式。另外，Kafka Connect的内存数据具有自己的数据类型，但后面我们会进一步看到，我们可以通过增加可插拔的转换器来支持不同的数据格式。

有一点需要注意的是，数据源与数据终点的数据格式通常具有自己的数据结构（Schema），当数据源的数据结构改变时，我们可能需要同时更新数据终点的数据结构。一个经典的例子为，当我们构建MySQL到Hive的数据管道时，如果MySQL增加了一列，那么当我们写入新数据到Hive时需要保证新的列也以某种形式添加到Hive中。

在支持不同数据格式之外，一个通用的数据集成框架应当能支持数据源与数据终点的不同特性。比如，Syslog是一个主动推送数据的数据源，而关系型数据库则要求我们主动拉取它的数据；HDFS只支持数据追加，而其他系统则允许追加和更新。

<br/>

#### 数据转换

构建数据管道时我们有如下两种数据转换方案：

- ELT（Extract-Transform-Load）：这种方案意味着数据管道负责做数据转换，这样做的好处是可以节省目标系统的转换时间和存储空间。但这种方案也有一个缺点，那就是数据管道的转换与下游的依赖需要时刻保持同步。比如，如果我们构建MongoDB到MySQL的数据管道，并且在数据管道中进行数据过滤并且移除某些域，那么MySQL中只能看到部分数据；如果后续我们需要访问这些缺失的数据域，那么数据管道需要重建并且重新处理历史数据。
- ELT（Extract-Load-Transform）：这种方案意味着数据管道做最少的转换（大部分情况下只是转换数据格式），终点的数据与源数据基本一样，这样做的好处是目标系统拥有极大的处理灵活性（因为能看到几乎原始的数据），并且由于数据处理与过滤只在目标系统上进行，减轻追溯问题的复杂程度。这种方案的缺点是目标系统会消耗较多的存储空间，并且的转换也会消耗CPU资源。

<br/>

#### 安全性

对于数据管道来说，安全性包含如下几个方面：

- 经过数据管道的数据是加密的吗？这个问题在跨数据中心时尤其突出。
- 谁允许对数据管道进行修改？
- 如果数据管道需要从访问受限的地方读取或写入数据，它是否能正确的进行身份验证？

Kafka支持对数据传输进行加密，以及支持身份验证（通过SASL）和授权。授权能够保证包含隐私数据的主题在未经授权的情况下不能被读取。另外，Kafka还提供授权与非授权的访问记录，并且能够跟踪主题中的事件来源以及谁进行了何种修改。

<br/>

#### 错误处理

认为数据始终是正确的是一件很危险的事情，我们需要提前考虑错误处理。例如，是否能阻止错误的记录进入管道？是否能从分析失败的记录恢复数据？错误记录是否能被修复以及重新处理？如果不良事件被当做正常事件处理了，但过了几天才发现，这会这么样？

由于Kafka能够在一段时间内保存所有事件，因此在需要的情况下我们可以回溯并且进行错误恢复。

<br/>

#### 耦合与敏捷

数据管道的一个重要作用就是将数据源与目标系统进行解耦，但在某些情况下如果不加以注意便会发生耦合：

- 专门定制管道：有一些公司会针对不同的应用专门定制管道，比如使用Logstash转储日志到Elasticsearch，使用Flume转储日志到HDFS，使用GoldenGate从Oracle获取数据并写入HDFS，等等…这样做会将数据管道与特定的终端耦合在一起，并且意味着每一个新系统都需要搭建新的数据管道。
- 结构元数据缺失：如果数据管道不包含结构元数据而且不允许结构变化，那么其实我们已经将产生数据的源系统与消费数据的目标系统耦合在一起。假如数据从Oracle数据库流向HDFS，DBA在数据库中添加了一列，在数据管道不包含结构元数据而且不允许结构变化的情况下，目标系统要么处理数据失败，要么需要升级应用代码。因此，数据管道应该能支持结构变化，每个独立的团队都可以根据需要来在合适的时刻修改应用逻辑。
- 过度处理：前面已经提到，一些数据处理会在数据管道中进行，毕竟数据管道负责把数据转移到不同的系统。但如果数据管道进行了过度的处理（比如数据清洗、数据聚合），那么会导致下游使用数据的系统与数据管道耦合在一起。最好的处理方式应该为，数据管道尽可能保留元数据的属性，只是做简单的格式转换，允许下游系统来决定他们需要什么样的数据。

<br/>

### 什么时候使用Kafka Connect？

当写入Kafka或者从Kafka读取时，我们可以使用传统的生产者/消费者客户端，或者使用Kafka Connect和connector。那应该怎么选择呢？

生产者/消费者客户端是嵌入到应用中的，换句话说，如果我们能够修改连接应用的代码，那么可以使用生产者/消费者客户端来写入和读取数据。而如果我们需要将Kafka连接到数据存储系统（或者将数据存储系统连接到Kafka），那么我们可以直接使用Connect以及相应的connector即可。如果对于某个数据存储系统，不存在与其匹配的connector，那么我们既可以使用生产者/消费者客户端，也可以使用Connect。但仍然推荐使用Connect，因为它开箱即用，提供了许多有用的功能，比如配置管理、位移存储、并行化、错误处理、不同数据类型支持等等。

<br/>

### Kafka Connect

Kafka Connect是Kafka的一部分，它提供了可扩展的方式将Kafka的数据转移到数据存储系统，或者从数据存储系统转移到Kafka。它提供了相应的API以及运行环境，以便我们开发connector插件。connector插件会被Kafka Connect执行并且用来转移数据。Kafka Connect以集群方式运行，每个节点均安装有connector插件，并且提供REST的API接口来配置和管理connector。数据源的connector只需要负责从源系统读取数据，并且转化为Connect数据对象；而目标系统的connector则负责接收Connect数据对象，以及写入到目标系统。

此外，Kafka Connect包含转换器来支持在Kafka中使用不同的数据格式，比如JSON或者Avro。这里提醒下，Kafka中的数据格式是可以独立于源系统（及其connector）与目标系统（及其connector）的。

下面来简单看下如何使用Kafka Connect。

<br/>

略

<br/>

<br/>

## 第八章：跨集群数据镜像

在之前系列文章中，我们讨论了一个Kafka集群的搭建、维护和使用，而在实际情况中我们往往拥有多个Kafka集群，而且这些Kafka集群很可能是相互隔离的。一般来说，这些集群之间不需要进行数据交流，但如果在某些情况下这些集群之间存在数据依赖，那么我们可能需要持续的将数据从一个集群复制到另一个集群。而由于“复制”这个术语已经被用于描述同一集群内的副本冗余，因此我们将跨集群的数据复制称为数据镜像（Mirroring）。另外，Kafka中内置的跨集群数据复制器称为MirrorMaker。

<br/>

### 跨集群数据镜像的用户场景

以下为跨集群数据镜像的一些典型用户场景：

- 区域集群与中心集群：很多公司往往有多个数据中心，而且每个数据中心维护独立的Kafka集群。一般的应用可能只需要跟本地集群通信即可，但存在一些应用需要所有集群的数据。比如，一个公司在每个城市都有一个数据中心，并且该中心维护相应城市的产品供需数据以及价格数据；这些数据需要汇总到一个中心集群以便进行公司维度的营利分析。
- 数据冗余：为了防止一个集群故障导致应用不可用，我们需要把数据同步到另一个集群，这样当一个集群出现故障，可以把应用的流量切换到备份集群。
- 云迁移：一般公司都维护有自己的数据中心，但随着云设施越来越便宜，很多公司会选择将服务迁移到云上。数据迁移与复制也是其中一个重要部分，我们可以使用Kafka Connect将数据库更新同步到本地Kafka集群，然后再把数据从本地Kafka集群同步到云上的Kafka集群。

<br/>

### 多集群架构

上面列举了多集群的用户场景，现在来看下多集群的常见架构。但在讨论架构前，先来了解跨集群通信的一些现实因素。

<br/>

#### 跨集群通信的现实因素

- 高延迟：由于集群间的距离较长以及网络拓扑节点增多，集群的通信延迟也会增加。
- 带宽有限：广域网（WAN）带宽通常比机房内带宽要小得多，并且可用带宽可能无时无刻都在变化。
- 高成本：无论是自己维护的集群还是云上的集群，集群间通信的成本都是非常高的。这是因为带宽有限并且增加带宽会带来昂贵的成本，而且服务提供商对于跨集群、跨区域、跨云的数据传输会额外收取费用。

Kafka的broker和生产者/消费者客户端都是基于一个集群来进行性能调优的，也就是说在低延迟和高吞吐的假设前提下，经过测试与验证从而得到了Kafka的超时和缓冲区默认值。因此，一般我们不推荐同一个集群的不同broker处于多个数据中心。大多数情况下，由于高延迟和网络错误，最好避免生产数据到另一个集群。当然，我们可以通过提高重试次数、增加缓冲区大小等手段来处理这些问题。

这么看，broker跨集群、生产者-broker跨集群这两种方案都被否决了，那么对于跨集群数据镜像，我们只剩下一种方案：broker-消费者跨集群。这种方案是最安全的，因为即便存在网络分区导致消费者不能消费数据，这些数据仍然保留在broker中，当网络恢复后消费者仍然可以读取。也就是说，无论网络状况如何，都不会造成数据丢失。另外，如果存在多个应用需要读取另一个集群的数据，我们可以在每个数据中心都搭建一个Kafka集群，使用集群数据镜像来只同步一次数据，然后应用从本地集群中消费数据，避免重复读取数据浪费广域网带宽。

下面是跨集群架构设计的一些准则：

- 每个数据中心都应该至少有一个Kafka集群；
- 集群间尽可能只同步一次数据；
- 跨集群消费数据由于跨集群生产数据。

<br/>

#### 1. 中心集群架构

下面是多个本地集群和一个中心集群的架构：

{% asset_img picture1.jpg %}

简单情况下只存在两个集群，即主集群和副本集群：

{% asset_img picture2.jpg %}

这种架构适用于，数据分布在多个数据中心而某些应用需要访问整体数据集。另外每个数据中心的应用可以处理本地数据，但无法访问全量数据。这种架构的主要优点在于，数据生产到本地，而且跨集群只复制一次数据（到中心集群）。只依赖本地数据的应用可以部署在本地集群，而依赖多数据中心的应用则部署在中心集群。这种架构也非常简单，因为数据流向是单向的，这使得部署、运维和监控非常容易。

它的主要缺点在于，区域的集群不能访问另一个集群的数据。比如，我们在每个城市维护一个Kafka集群来保存银行的用户信息和账户历史，并且将这些数据同步到中心集群以便做银行的商业分析。当用户访问本地的银行分支网站时，这些请求可以被分发到本地集群处理；但如果用户访问异地的银行分支网站时，要么该异地集群跟中心集群通信（此种方式不建议），要么直接拒绝请求（是的非常尴尬）。

<br/>

#### 2. 多活架构

这种架构适用于多个集群共享数据，如下所示：

{% asset_img picture3.jpg %}

此架构主要优点在于，每个集群都可以处理用户的任何请求并且不阉割产品功能（与前一种架构对比），而且就近处理用户请求，响应时间可以大大降低。其次，由于数据冗余与弹性控制，一个集群出现故障，可以把用户请求导流到别的集群进行处理。

此架构主要缺点在于，由于多个集群都可以处理用户请求，异步的数据读取和更新无法保证全局数据一致性。下面列举一些可能会遇到的挑战：

- 如果用户发送一个事件到一个集群，然后从其他集群读取事件信息，那么由于事件复制延迟，很有可能读取不到该事件。比如，用户添加一本书到心愿单后，访问心愿单却看不到添加的书。为了解决这个问题，研发人员可能会将用户与集群进行绑定，使用同一个集群来处理用户请求（当然在集群故障情况下会转移）。
- 一个用户在一个数据中心订购了书 A ， 而第二个数据中心几乎在同一时间收到了该用户订购书 B 的订单， 在经过数据镜像之后 ， 每个数据中心都包含了这两个事件。 两个数据中心的应用程序需要知道如何处理这种情况。 我们是否应该从中挑选一个作为“正确”的事件？如果是这样， 我们需要在两个数据中心之间定义一致的 规则， 用于确定哪个事件才是正确的 。 又或者把两个都看成是正确的事件，将两本书都发给用户，然后设立一个部门专门来处理退货问题？ Amazon 就是使用这种方式来处理冲突的，但对于股票交易部门来说，这种方案是行不通的。如何最小化冲突以及如何处理冲突要视具体情况而定。 总之要记住，如果使用了这种架构 ， 必然会遇到冲突问题，还要想办注解决它们。

如果能够很好地处理在从多个位置异步读取数据和异步更新数据时发生的冲突问题，那么我们强烈建议使用这种架构。 这种架构是我们所知道的最具伸缩性、弹性、灵活性和成本优势的解决方案。 所以，它值得我们投入精力去寻找一些办法，用于避免循环复制、把相同用户的请求粘在同一个数据中心， 以及在发生冲突时解决冲突。

多活架构的另一个挑战是，如果存在多个数据中心，那么每一对中心都需要通信链路。也就是说，如果有5个数据中心，那么总共需要部署20个镜像进程来处理数据复制；如果考虑高可用，那么可能需要40个。

另外，我们需要避免事件被循环复制和处理。对于这个问题，我们可以将一个逻辑概念的主题拆分成多个物理主题，并且一个物理主题与一个数据中心对应。比如，users这个逻辑主题可以拆分成SF.users和NYC.users这两个物理主题，每个主题对应一个数据中心；NYC的镜像进程从SF的SF.users读取数据到本地，SF的镜像进程从NYC的NYC.users读取数据到本地。因此每个事件都只会被复制一次，而且每个数据中心都包含SF.users和NYC.users主题，并且包含全量的users数据。消费者如果需要获取全量的users数据，那么需要消费所有本地.users主题的数据。

需要提醒的是，Kafka正在计划添加记录头部，允许我们添加标记信息。我们在生产消息时可以加上数据中心的标记，这样也可以避免循环数据复制。当然，我们也可以自己在消息体中增加标记信息进行过滤，但缺点是当前的镜像工具并不支持，我们得自己开发复制逻辑。

<br/>

#### 3. 冷热互备架构

有时候，多集群是为了防止单点故障。比如说，我们可能有两个集群，其中集群A处于服务状态，另一个集群B通过数据镜像来接收集群A所有的事件，当集群A不可用时，B可以启动服务。在这种场景中，集群B包含了数据的冷备份。架构如下所示：

{% asset_img picture4.jpg %}

这种架构的优点在于搭建简单并且适用于多种场景。我们只需搭建第二个集群，设置一个镜像进程来将源集群的所有事件同步到该集群即可，并且不用担心发生数据冲突。缺点在于，我们浪费了一个集群资源，因为集群故障通常很少发生。一些公司会选择搭建低配的备份集群，但这样会存在一个风险，那就是无法保证出现紧急情况时该备份集群是否能支撑所有服务；另一些公司则选择适当利用备份集群，那就是把一些读取操作转移到备份集群。

集群故障转移也具有一些挑战性。但无论我们选择何种故障转移方案，SRE团队都需要进行日常的故障演练。因为，即便今天故障转移是有效的，在进行系统升级之后很可能失效了。一个季度进行一次故障转移演练是最低限度，强大的SRE团队会演练更频繁，Netflix著名的Chaos Monkey玩的更溜，它会随机制造故障，也就是说故障每天都可能发生。

下面来看下故障转移比较具有挑战性的地方。

**数据损失与不一致**

很多Kafka的数据镜像解决方案都是异步的，也就是说备份集群不会包含主集群最新的消息。在一个高并发的系统中，备份集群可能落后主集群几百甚至上千条消息。假如集群每秒处理100万条消息，备份集群与主集群之间有5ms的落后，那么在理想情况下备份集群也落后将近5000条消息。因此，我们需要对故障转移时的数据丢失做好准备。当然在故障演练时，我们停止主集群之后，可以等待数据镜像进程接收完剩余的消息，再进行故障转移，避免数据丢失。另外，Kafka不支持事务，如果多个主题的数据存在关联性，那么在数据丢失的情况下可能会导致不一致，因此应用需要注意处理这种情况。

**故障转移的开始消费位移**

在故障转移中，其中一个挑战就是如何决定应用在备份集群的开始消费位移。下面来讨论几个可选的方案。

- 自动位移重置：Kafka消费者可以配置没有已提交位移时的行为，要么从每个分区的起始端消费，要么从每个分区的最末端消费。如果我们的消费者提交位移到Zookeeper，而且没有对Zookeeper中的位移数据进行镜像备份，那么我们需要从这两个选项中做出选择。选择从起始端开始消费的话，可能会存在大量重复的消息；选择从最末端消费的话，可能会存在消息丢失。如果这两种情况可以忍受的话，那么建议选择这种方案，因为这种方案非常简单。
- 复制位移主题：如果我们使用0.9或者更高版本的Kafka消费者，消费者会提交位移到一个特殊的主题，_consumer_offsets。如果我们复制这个主题到备份集群，那么备份集群的消费者可以从已提交的位移处开始消费。这种方案也很简单，但是有一些情况需要注意。首先，主集群和备份集群的消息位移不能保证是一样的。举个例子，我们在主集群中只保留3天的数据，在主题创建并且使用了一个星期之后，我们开始进行备份集群的数据镜像；在这个场景中，主集群的最新消息位移可能到达57000000，而备份集群的最新消息位移是0，并且由于主集群中老的数据已经被过期删除了，备份集群的消息位移跟主集群始终是不一样的。其次，即便我们在创建主题就进行数据镜像，由于生产者失败重试，仍然会导致不同集群的消息位移是不同的。最后，即便主集群和备份集群的消息位移完全一致，由于主集群和备份集群存在一定的消息落后并且Kafka不支持事务，消费者提交的消息位移可能在相应消息之前或之后到达。因此，在故障转移时消费者可能根据位移找不到匹配的消息，或者位移落后于主集群。总的来说，如果备份集群的提交位移比主集群的提交位移更老，或者由于重试导致备份集群的消息比主集群的消息多，那么会存在一定的数据重复消费；如果备份集群的提交位移没有匹配到相应的消息，那么我们可能仍然需要从主题起始端或者最末端进行消费。因此，这种方案能够减少数据重复消费或者数据丢失，但也不能完全避免。
- 基于时间的故障转移：如果我们使用0.10.0或者更高版本的Kafka消费者，每条消息都会包含发送到Kafka的时间戳。而且，0.10.1.0或者更高版本的broker会建立一个索引，并且提供一个根据时间戳来查询位移的API。因此，假如我们知道故障在某个时间发生，比如说为早上4:05，那么我们可以让备份集群的消费者从早上4:03处开始消费数据，虽然这样会有两分钟的数据重复消费，但至少数据没有丢失。这个方案的唯一问题是，我们怎么告诉备份集群的消费者从特定时间点开始消费呢？一个解决思路是，我们在应用代码中支持指定开始消费的时间，然后使用API来获取该时间对应的位移，然后从该位移处开始消费处理。但如果应用代码没有支持这种功能，我们可以自己写一个小工具，该工具接收一个时间戳，然后使用API来获取所有主题分区的位移，最后提交这些位移，这样备份集群的消费组在启动时会自动获取位移，然后进行消费处理。这种方案是最优的。
- 外部位移映射：在上面讨论复制位移主题的时候，曾提到一个最大的挑战是主集群和备份集群的消息位移不一致。基于这个问题，一些公司选择开发自己的数据镜像工具，并且使用外部存储系统来存储集群间的消息位移映射。比如，主集群中位移为495的消息对应于备份集群中位移为500的消息，那么在外部存储系统中记录（495，500），这样在故障转移时我们可以基于主集群的已提交位移和映射来得到备份集群中的提交位移。但这种方案没有解决位移比消息提前到达备份集群的问题。这种方案比较复杂，升级集群然后使用基于时间的故障转移可能更便捷。

**故障转移之后**

假如故障顺利转移到备份集群，并且备份集群正常工作，那么原主集群应该怎么处理呢？可能需要将其转化为备份集群。你可能会想，能不能简单修改数据镜像工具，让其换个同步方向，从新的主集群同步数据到老的主集群？这样会导致两个问题：

- 我们如何得知从什么地方开始进行数据镜像呢？这个问题跟故障转移时消费者不知道消费位移的问题是一样的，而且解决方案也会存在消息重复或者丢失的问题。
- 如前所述，老的主集群可能会包含备份集群没有同步的数据更新，如果只是简单的将新主集群的数据同步回来，那么这两个集群又会发生不一致的情况。

因此，最简单的解决方案是，清除老主集群的所有状态和数据，然后重新与新主集群进行数据镜像，这样可以保证这两个集群的状态是一致的。

**其他事项**

故障转移还有一个需要注意的地方是，应用如何切换与备份集群进行通信？如果我们在代码中直接硬编码主集群的broker，那么故障转移比较麻烦。因此，很多公司会创建一个DNS名称来解析到主集群的broker，当故障转移时将DNS解析到备份集群的broker。由于Kafka客户端只需要成功连接到集群的一个broker便可通过该broker发现整个集群，因此我们创建3个左右的DNS解析到broker即可。

<br/>

#### 4. 延伸集群

延伸集群主要用来防止单个数据中心故障导致Kafka服务不可用，其解决方案为：将一个Kafka集群分布在多个数据中心。因此延伸集群与其他集群方案有本质的区别，它就是一个Kafka集群。在这种方案中，我们不需要数据镜像来同步，因为Kafka本身就有复制机制，并且是同步复制的。在生产者发送消息时，我们可以通过配置分区机架信息、min.isr、acks=all来使得数据写入到至少两个数据中心副本后，才返回成功。

这种方案的优点是，多个数据中心的数据是实时同步的，而且不存在资源浪费问题。由于集群跨数据中心，为了得到最好的服务性能，数据中心间需要搭建高质量的通信设施以便得到低延迟和高吞吐，部分公司可能无法提供。

另外需要注意的是，一般需要3个数据中心，因为Kafka依赖的Zookeeper需要奇数的节点来保证服务可用性，只要有超过一半的节点存活，服务即可用。如果我们只有两个数据中心，那么肯定其中一个数据中心拥有多数的Zookeeper节点，那么该数据中心发生故障的话服务便不可用；如果拥有三个数据中心并且Zookeeper节点均匀分布，那么其中一个数据中心发生故障，服务仍然可用。

<br/>

### MirrorMaker 

Kafka内置了一个用于集群间做数据镜像的简单工具–MirrorMaker，它的核心是一个包含若干个消费者的消费组，该消费组从指定的主题中读取数据，然后使用生产者把这些消息推送到另一个集群。每个消费者负责一部分主题和分区，而生产者则只需要一个，被这些消费者共享；每隔60秒消费者会通知生产者发送消息数据，然后等待另一个集群的Kafka接收写入这些数据；最后这些消费者提交已写入消息的位移。MirrorMaker保证数据不丢失，而且在发生故障时不超过60秒的数据重复。内部架构如下所示：

{% asset_img picture5.jpg %}

<br/>

#### 如何配置

略