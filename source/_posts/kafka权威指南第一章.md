---
title: kafka权威指南第一章
categories:
  - kafka权威指南读书笔记
abbrlink: 6e3b6e5d
date: 2019-02-15 16:14:40
---

### 序

和mq的不同点：

1. Kafka 以集群的方式运行， 可以自由伸缩， 处理公司的所有应用 程 序。 Kafka 集群并不是一组独立 运行的 broker， 而是一个可以灵活伸 缩的中心平台， 可以 处理整个公司所有的数 据流。
2. Kafka 可以按照你的要求存储 数据， 保存多久都可以。 作为数据连接层， Kafka 提供了数据传递保证 可复制、持久化， 保留多长时间完全可以由你来决定。
3. Mq只会传递 消息， 而 Kafka 的流式处理能力让你 只用很少的代码就能 够动态地处理派生流 和数据集

<br/>

实时版本的hadoop

Hadoop 可以存储和定期处理大 量的数据文件， 而 Kafka 可以存储 和持续处理大型的数据 流。它们之间的最大不同体 现在持续的低延迟处理 和批处理之间 的差异上。 Hadoop 和大数据主要应用在数 据分析上， 而 Kafka 因其低延迟的特点更适 合用 在核心的业务应用上。 业务事件时刻在发生， Kafka 能够及时对这些事件 作出响应， 基于 Kafka 构建的服务直接为业务 运营提供支撑， 提升用户体验。

<br/>

以数据流为中心的架构

<br/>

## 第一章 初识 kafka

<br/>

### 一、基本特性

<br/>

**key的幂等性**

每个消息都对一个一个key，key也是一个字节数组， 与消息一样， 对于 Kafka 来说也没有特殊的含义。 当消息以一种可控的方式写入不同的分区时， 会用到key。 最简单的例子就是为键生成一个一致性散列值， 然后使用散列值对 topic 分区数进行取模， 为消息选取分区 。这样可以保证具有 相同键的消息总是被写到相同的分区上，也就是保证**幂等性**

<br/>

**批次**

为了提高效率， 消息被分批次写入 Kafka。 批次就是一组消息， 这些消息属于同一个主题 和分区。 如果每一个消息都单独穿行于网络， 会导致大量的网络开销， 把消息分成批次传 输**可以减少网络开销**。 不过， 这要在时间延迟和吞吐量之间作出权衡：批次越大， 单位时间内处理的消息就越多（吞吐量就越大）， 单个消息的传输时间就越长（时间延迟变大）。 批次数据会被压缩， 这样可以提升数据的传输和存储能力， 但要做更多的计算处理。

<br/>

**消息的序列化方式**

定义良好的模式， 并把它们存放在公共仓库，这样可以解除生产者和消费者的耦合性。像 JSON 和 XML 这些简单的系统， 不仅易用， 而且可读性好。 不过， 它们 缺乏强类型处理能力， 不同版本之间的兼容性也不是很好。 Kafka 的许多开发者喜欢使用 Apache Avro；

<br/>

**分区器**

保证key的幂等性，可自定义

<br/>

**偏移量**

偏移量是另 一种元数据 ， 它是一个不 断递增的整 数值， 在创建消息 时， Kafka 会把它添加 到消息里。 在给定的分 区里， 每个消息的偏移量都是唯一的。 消费 者把每个分 区最后读取 的消息偏移量保存在 Zookeeper 或 Kafka 上， 如果消费者关闭或重启， 它的读取状态不会丢失 。

<br/>

**consumer group **

一个或 多个消费者 共同读取一 个主题。 群组保证每个分区只能被 一个消费者 使用，消费者和分区之间通常有一种**所有权关系**，**每个消费者会固定读取每个分区的消息**。

{% asset_img firure1-6.png %}

<br/>

**broker 和集群**

一个独立的 Kafka 服务器被称 为 broker。

broker 是集群的组成部分。 每个集群都有一个 broker 同时充当了 集群控制器的角色（自动从集群的活跃成员中选举出来）。 控制器负责管理工作， 包括将分区分配给broker和监控 broker ； 

<br/>

在集群中，每一个topic 的单个 partition 也都还有自己的leader(一台broker)。 每个partition可以分配给多个broker， 这就是副本机制（见图 1-7 ）。 这种副本机制为每个partition提供了消息冗余 ， 如果有一个 broker 失效， 其他 broker可以接管，不过，相关的消费 者 和生产者都 要重新连接 到新的leader 。

{% asset_img firure1-7.png %}

<br/>

{% asset_img firure1-z.png %}

<br/>

<br/>

**多集群**

原因：

1. 数据类型分离
2. 安全需求隔离
3. 多数据中心（容灾恢复）

<br/>

问题：

Kafka 的消息复制机制只能在单个集群里进行， 不能在多 个集群之间进行。

<br/>

解决办法：

- MirrorMaker

Mirror Maker的核心组件包含了 一个生产者和一个消费者， 两者之间通过一个队列相连。 消费者从一个集群读取消息， 生产者把消息发送到另一个集群上。 图 1-8 展示了 一个使 用 MirrorMaker 的例子， 两个“本地”集群的消息被聚集到一个“聚合”集群上， 然后将 该集群复制到其他数据中心。 不过， 这种方式在创建复杂的数据管道方面显得有点力不从 心。

{% asset_img firure1-8.png %}

<br/>

<br/>

### 二、为什么选择kafka

<br/>

1. 支持多个生产者

Kafka 可以无缝地支持多个生产者， 不管客户端在使用单个主题还是多个主题。 所以它很 适合用来从多个前端系统收集数据， 并以统一的格式对外提供数据。 例如， 一个包含了多个微服务的网站， 可以为页面视图创建一个单独的主题， 所有服务都以相同的消息格式向该主题写入数据。 消费者应用程序会获得统一的页面视图， 而无需协调来自不同生产者的 数据流。

<br/>

1. 支持多个消费者

除了支持多个生产者外， Kafka 也支持多个消费者从一个单独的消息流上读取数据， 而且 消费者之间直不影响。 这与其他队列系统不同， 其他队列系统的消息一旦被一个客户端读取，其他客户端就无法再读取它。 另外， 多个消费者可以组成一个群组， 它们共同读取一个topic，并保证整个群组对每个给定的消息只处理一次。

<br/>

1. 基于磁盘的数据存储

Kafka 不仅支持多个消费者， 还允许消费者非实时地读取消息，这要归功于 Kafka 的数据保留特性。消息被提交到磁盘， 根据设置的保留规则进行保存。 每个主题可以设置单独的保留规则， 以便满足不同消费者的需求，各个主题可以保留不同数量的消息。 消费者可能会因为处理速度慢或突发的流量高峰导致无陆及时读取消息， 而持久化数据可以保证数据 不会丢失。消费者可以在进行应用程序维护时离线一小段时间， 而无需担心消息丢失或堵塞在生产者端。 消费者可以被关闭， 但消息会继续保留在 Kafka 里。消费者可以从上次中断的地方继续处理消息。

<br/>

1. 可伸缩性

为了能够轻松处理大量数据， Kafka 从一开始就被设计成一个具有灵活伸缩性的系统。 用 户在开发阶段可以先使用单个 broker， 再扩展到包含 3 个 broker 的小型开发集群， 然后随着数据量不断增长， 部署到生产环境的集群可能包含上百个broker。 对在线集群进行扩展丝毫不影响整体系统的可用性。也就是说，一个包含多个 broker 的集群， 即使个别 broker 失效， 仍然可以持续地为客户提供服务。 要提高集群的容错能力， 需要配置较高的复制系数。

<br/>

1. 高性能

通过横向扩展生产者、消费者和 broker, Kafka 可以轻松处理巨大的消息流。 在处理大量数据的同时，它还能保证亚秒级的消息延迟。

<br/>

### 三、数据生态系统

<br/>

#### 使用场景

1. 活动跟踪，

网站前端捕获用户行为，然后发送到kafka ，由后端app 读取，然后进行分析处理，生成报告， 或者为machine learning 提供数据

<br/>

1. 传递消息

应用程序向用户发送通知（比如邮件）就是通过传递消息来实现的。我们可以把邮件信息的发送，做成一个独立的公用服务，这个服务消费kafka的消息，然后做一些信息的包装（增加祝福语等）、多条信息的整合等，然后直接发送给用户，信息的生产者，不需要关心发送邮件的格式等问题，只需要把它想要发送的邮件信息发送到kafka ，后续会有公共服务进行后续处理；

<br/>

1. 度量指标和日志 记录

Kafka 也可以用于收集应用程序和**系统度量指标**以及日志。Kafka 支持多个生产者 的特性在这个时候就可以派上用场。 应用程序定期把度量指标发布到 Kafka 主题上， 监控系统或告 警系统读取这些消息

日志消息也可以被发布到Kafka 主题上， 然后被路由到专门的日志搜索系统（比如 Elasticsearch ）或安全分析应用程序。 更改目标系统（比如日志存储系统）不会影响到前端应用或聚合方法， 这是 Kafka 的另一个优点。

<br/>

1. 提交日志 （databus）

Kafka 的基本概念来源于提交日志， 所以使用 Kafka 作为提交日志是件顺理成章的事。 我 们可以把数据库的更新发布到 Kafka 上，应用程序通过监控事件流来接收数据库的实时更新。这种变更日志流也可以用于把数据库的更新复制到远程系统上，或者合并多个应用程序的更新到一个单独的数据库视图上。数据持久化为变更日志提供了缓冲区， 也就是说 ， 如果消费者应用程序发生故障， 可以通过重放这些日志来恢复系统状态。 另外，紧凑型日志主题只为每个键保留一个变更数据，永远不会过期， 所以可以长时间使用， 不需要担心消息过期问题。

<br/>

1. 流处理

实时计算，flink 